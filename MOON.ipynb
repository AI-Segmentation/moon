{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyunwoo Moon's Amazing Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "import math\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE 디코딩 함수\n",
    "def rle_decode(mask_rle, shape):\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)\n",
    "\n",
    "# RLE 인코딩 함수\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten()\n",
    "\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "\n",
    "    \n",
    "    # 픽셀값이 1,2인 픽셀 삭제\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for i in range(1, len(runs), 2):  # 짝수번째 인덱스만 접근\n",
    "        if runs[i] not in [1, 2]:\n",
    "            result.extend([runs[i-1], runs[i]])  # 해당 인덱스와 그 전 인덱스를 추가\n",
    "    \n",
    "    return ' '.join(str(x) for x in result)\n",
    "    \"\"\"\n",
    "    return ' '.join(str(x) for x in runs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 노이즈 제거 적용\n",
    "def apply_noise_reduction(image, kernel_size=(3, 3)):\n",
    "    blurred_image = cv2.GaussianBlur(image, kernel_size, 0)\n",
    "    return blurred_image\n",
    "\n",
    "# 샤프닝 적용\n",
    "def apply_sharpening(image):\n",
    "    kernel = np.array([[0, -1, 0],\n",
    "                       [-1, 5, -1],\n",
    "                       [0, -1, 0]])\n",
    "    sharpened_image = cv2.filter2D(image, -1, kernel)\n",
    "    return sharpened_image\n",
    "\n",
    "# 화소 보정 적용\n",
    "def apply_pixel_correction(image, alpha, beta):\n",
    "    corrected_image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    return corrected_image\n",
    "\n",
    "class SatelliteDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, infer=False):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.iloc[idx, 1]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 추론용 데이터셋인 경우\n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                # 이미지 품질 향상을 위해 노이즈 제거 적용\n",
    "                image = apply_noise_reduction(image)\n",
    "                # 이미지 품질 향상을 위해 샤프닝 적용\n",
    "                image = apply_sharpening(image)\n",
    "                # 이미지 품질 향상을 위해 화소 보정 적용\n",
    "                #image = apply_pixel_correction(image, alpha=1.5, beta=30)\n",
    "                # 이미지 변환 적용\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "\n",
    "        mask_rle = self.data.iloc[idx, 2]\n",
    "        mask = rle_decode(mask_rle, (image.shape[0], image.shape[1]))\n",
    "\n",
    "        if self.transform:\n",
    "            # 이미지 품질 향상을 위해 노이즈 제거 적용\n",
    "            image = apply_noise_reduction(image)\n",
    "            # 이미지 품질 향상을 위해 샤프닝 적용\n",
    "            image = apply_sharpening(image)\n",
    "            # 이미지 품질 향상을 위해 화소 보정 적용\n",
    "            #image = apply_pixel_correction(image, alpha=1.5, beta=30)\n",
    "            \n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = A.Compose(\n",
    "    [\n",
    "        # 랜덤 크롭 추가\n",
    "        A.RandomCrop(224, 224),\n",
    "        \n",
    "        # 랜덤 회전 추가 (±45도 범위에서 랜덤하게 회전)\n",
    "        A.Rotate(limit=45, p=0.5),\n",
    "\n",
    "        # 랜덤 상하 대칭 추가\n",
    "        #A.VerticalFlip(p=0.5),\n",
    "\n",
    "        # 이미지 크기 조정\n",
    "        A.Resize(224, 224),\n",
    "\n",
    "        # 명암 대비 조정과 밝기 조절\n",
    "        #A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), always_apply=True),\n",
    "\n",
    "        # 색감 조정\n",
    "        #A.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1, always_apply=True),\n",
    "        \n",
    "        A.Normalize(),\n",
    "\n",
    "        # 이미지를 텐서로 변환\n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_test = A.Compose(\n",
    "    [\n",
    "        # 이미지 크기 조정\n",
    "        A.Resize(224, 224),\n",
    "        \n",
    "        A.Normalize(),\n",
    "\n",
    "        # 이미지를 텐서로 변환\n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = SatelliteDataset(csv_file='./train.csv', transform=transform_train)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net의 기본 구성 요소인 Double Convolution Block을 정의합니다.\n",
    "def double_conv(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "# 간단한 U-Net 모델 정의\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        self.dconv_down1 = double_conv(3, 64)\n",
    "        self.dconv_down2 = double_conv(64, 128)\n",
    "        self.dconv_down3 = double_conv(128, 256)\n",
    "        self.dconv_down4 = double_conv(256, 512)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        \n",
    "\n",
    "        self.dconv_up3 = double_conv(256 + 512, 256)\n",
    "        self.dconv_up2 = double_conv(128 + 256, 128)\n",
    "        self.dconv_up1 = double_conv(128 + 64, 64)\n",
    "\n",
    "        self.conv_last = nn.Conv2d(64, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "        \n",
    "        conv3 = self.dconv_down3(x)\n",
    "        x = self.maxpool(conv3)   \n",
    "\n",
    "        x = self.dconv_down4(x)\n",
    "\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv3], dim=1)\n",
    "\n",
    "        x = self.dconv_up3(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv2], dim=1)       \n",
    "\n",
    "        x = self.dconv_up2(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv1], dim=1)   \n",
    "\n",
    "        x = self.dconv_up1(x)\n",
    "\n",
    "        out = self.conv_last(x)\n",
    "\n",
    "        return out\n",
    "\n",
    "# 깊은 U-Net 모델 정의\n",
    "class DeepUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepUNet, self).__init__()\n",
    "        self.dconv_down1 = double_conv(3, 64)\n",
    "        self.dconv_down2 = double_conv(64, 128)\n",
    "        self.dconv_down3 = double_conv(128, 256)\n",
    "        self.dconv_down4 = double_conv(256, 512)\n",
    "        self.dconv_down5 = double_conv(512, 1024)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        \n",
    "\n",
    "        self.dconv_up4 = double_conv(1024 + 512, 512)\n",
    "        self.dconv_up3 = double_conv(512 + 256, 256)\n",
    "        self.dconv_up2 = double_conv(256 + 128, 128)\n",
    "        self.dconv_up1 = double_conv(128 + 64, 64)\n",
    "\n",
    "        self.conv_last = nn.Conv2d(64, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "        \n",
    "        conv3 = self.dconv_down3(x)\n",
    "        x = self.maxpool(conv3)   \n",
    "\n",
    "        conv4 = self.dconv_down4(x)\n",
    "        x = self.maxpool(conv4)\n",
    "\n",
    "        x = self.dconv_down5(x)\n",
    "\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv4], dim=1)\n",
    "\n",
    "        x = self.dconv_up4(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv3], dim=1)\n",
    "\n",
    "        x = self.dconv_up3(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv2], dim=1)       \n",
    "\n",
    "        x = self.dconv_up2(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv1], dim=1)   \n",
    "\n",
    "        x = self.dconv_up1(x)\n",
    "\n",
    "        out = self.conv_last(x)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNet / DeepUNet\n",
    "select_model = 'DeepUNet'    # 사용할 모델 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nothing : -1 / Training : 0 / Inference : 1 / Traing & Inference : 2\n",
    "mode = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode in [0,2]:\n",
    "    # model 초기화\n",
    "    if select_model == 'UNet':\n",
    "        model = UNet().to(device)\n",
    "    elif select_model == 'DeepUNet':\n",
    "        model = DeepUNet().to(device)\n",
    "        \n",
    "    # 가중치 설정\n",
    "    building_weight = 3.0  # 건물이 있는 영역에 대한 가중치\n",
    "    non_building_weight = 1.0  # 건물이 없는 영역에 대한 가중치 \n",
    "\n",
    "    # loss function과 optimizer 정의\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([non_building_weight/building_weight]).to(device))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # 최적 모델 저장을 위한 변수 초기화\n",
    "    best_val_loss = 1  # 최저 손실값을 저장할 변수\n",
    "    patience = 2  # 성능이 개선되지 않을 때 학습 종료 기다리는 횟수\n",
    "\n",
    "    # training loop\n",
    "    for epoch in range(50):  # 최대 에폭\n",
    "        # 최소 15 에폭 학습\n",
    "        if epoch < 15 : \n",
    "            patience = 2\n",
    "            \n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for images, masks in tqdm(dataloader):\n",
    "            images = images.float().to(device)\n",
    "            masks = masks.float().to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch {epoch+1}, Loss: {epoch_loss/len(dataloader)}')\n",
    "\n",
    "        # 유의미한 성능 개선이 있을 경우\n",
    "        if best_val_loss - epoch_loss/len(dataloader) > 0.0001:   \n",
    "            patience = 2\n",
    "            best_val_loss = epoch_loss/len(dataloader)    # 최상의 Loss값 갱신\n",
    "            torch.save(model, f'./model(' + select_model + ').pt')   # 최적의 모델 갱신\n",
    "\n",
    "        # 미미한 성능 개선이 있을 경우 혹은 성능 개선이 없을 경우    \n",
    "        else:\n",
    "            patience = patience - 1 \n",
    "            best_val_loss = epoch_loss/len(dataloader)    # 최상의 Loss값 갱신\n",
    "            torch.save(model, f'./model(' + select_model + ').pt')   # 최적의 모델 갱신\n",
    "            # 유의미한 성능 개선 3번 연속 없을 경우 학습 종료\n",
    "            if patience < 0:\n",
    "                break\n",
    "\n",
    "    print('Training is Ended!! Best Loss: ' + str(best_val_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SatelliteDataset(csv_file='./test.csv', transform=transform_test, infer=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/15160 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference by model(DeepUNet).pt\n",
      "threshold : 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15160/15160 [05:07<00:00, 49.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# 모델 기반 후처리 함수\n",
    "post_process_limit = 5    # 노이즈 취급 범위\n",
    "\n",
    "def post_process_mask(masks):\n",
    "    processed_masks = []\n",
    "    kernel = np.ones((post_process_limit, post_process_limit), np.uint8)\n",
    "    \n",
    "    for mask in masks:\n",
    "        # 작은 객체를 제거하거나 작은 구멍을 메우는 데 사용\n",
    "        mask_processed = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "        # 작은 구멍을 메우거나 끊어진 객체를 연결하는 데 사용\n",
    "        # mask_processed = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "        processed_masks.append(mask_processed)\n",
    "\n",
    "    return processed_masks\n",
    "\n",
    "if mode in [1,2]:\n",
    "    model = torch.load('model(' + select_model + ').pt')\n",
    "    print('Inference by model(' + select_model + ').pt')\n",
    "\n",
    "    value_Threshold = 0.4    # 시작 임계값  \n",
    "    end_Threshold = 0.4    # 끝 임계값\n",
    "    \n",
    "    while value_Threshold <= end_Threshold:\n",
    "            \n",
    "        threshold = value_Threshold   # 임계값 / Original Threshold = 0.35\n",
    "        \n",
    "        print('threshold : ' + str(threshold))\n",
    "        \n",
    "        value_Threshold += 0.1    # 임계값 증가폭\n",
    "        value_Threshold = math.floor(value_Threshold * 1000) / 1000\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            result = []\n",
    "            for images in tqdm(test_dataloader):\n",
    "                images = images.float().to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                masks = torch.sigmoid(outputs).cpu().numpy()\n",
    "                masks = np.squeeze(masks, axis=1)\n",
    "                masks = (masks > threshold).astype(np.uint8)\n",
    "\n",
    "                # 모델 기반 후처리를 수행하여 작은 노이즈 제거\n",
    "                processed_masks = post_process_mask(masks)\n",
    "                \n",
    "                #for i in range(len(images)):\n",
    "                for processed_mask in processed_masks:\n",
    "                    #mask_rle = rle_encode(masks[i])\n",
    "                    mask_rle = rle_encode(processed_mask)\n",
    "                    if mask_rle == '': # 예측된 건물 픽셀이 아예 없는 경우 -1\n",
    "                        result.append(-1)\n",
    "                    else:\n",
    "                        result.append(mask_rle)\n",
    "        submit = pd.read_csv('./sample_submission.csv')\n",
    "        submit['mask_rle'] = result\n",
    "    \n",
    "        temp = './submit(' + select_model + ' ' + str(threshold) + ' ' + str(post_process_limit) + ').csv'\n",
    "        submit.to_csv(temp, index=False)\n",
    "        print(temp + ' is created!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if mode in [1,2]:\n",
    "#    submit = pd.read_csv('./sample_submission.csv')\n",
    "#    submit['mask_rle'] = result\n",
    "#    \n",
    "#    temp = './submit(' + select_model + ' ' + str(threshold) + ').csv'\n",
    "#    submit.to_csv(temp, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp = './submit(' + select_model + ' ' + str(threshold) + ').csv'\n",
    "#submit.to_csv(temp, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_csv1 = ''     \n",
    "submit_csv2 = ''\n",
    "submit_csv3 = ''\n",
    "\n",
    "def visual(image_idx, submit_csv1, submit_csv2, submit_csv3):\n",
    "# Decoding - submit_csv1  \n",
    "    if submit_csv1 != '':\n",
    "        # CSV 파일 읽기\n",
    "        df = pd.read_csv(submit_csv1, header=None)\n",
    "\n",
    "        # 이미지 파일 이름과 마스크 정보 파싱\n",
    "        image_names = df[0].values\n",
    "        mask_info = df[1].values\n",
    "\n",
    "        image_name = image_names[image_idx + 1]\n",
    "        mask_str = mask_info[image_idx + 1]\n",
    "        print(image_names[image_idx + 1])\n",
    "\n",
    "        # 이미지 파일과 마스크 정보 출력\n",
    "        image = cv2.imread('./test_img/' + image_name + '.png')\n",
    "        mask_decoded1 = rle_decode(mask_str, shape=(224, 224))\n",
    "    \n",
    "# Decoding - submit_csv2 \n",
    "    if submit_csv2 != '':\n",
    "        # CSV 파일 읽기\n",
    "        df = pd.read_csv(submit_csv2, header=None)\n",
    "\n",
    "        # 이미지 파일 이름과 마스크 정보 파싱\n",
    "        image_names = df[0].values\n",
    "        mask_info = df[1].values\n",
    "\n",
    "        image_name = image_names[image_idx + 1]\n",
    "        mask_str = mask_info[image_idx + 1]\n",
    "\n",
    "        # 이미지 파일과 마스크 정보 출력\n",
    "        image = cv2.imread('./test_img/' + image_name + '.png')\n",
    "        mask_decoded2 = rle_decode(mask_str, shape=(224, 224))\n",
    "        \n",
    "# Decoding - submit_csv3   \n",
    "    if submit_csv3 != '':\n",
    "        # CSV 파일 읽기\n",
    "        df = pd.read_csv(submit_csv3, header=None)\n",
    "\n",
    "        # 이미지 파일 이름과 마스크 정보 파싱\n",
    "        image_names = df[0].values\n",
    "        mask_info = df[1].values\n",
    "\n",
    "        image_name = image_names[image_idx + 1]\n",
    "        mask_str = mask_info[image_idx + 1]\n",
    "\n",
    "        # 이미지 파일과 마스크 정보 출력\n",
    "        image = cv2.imread('./test_img/' + image_name + '.png')\n",
    "        mask_decoded3 = rle_decode(mask_str, shape=(224, 224))\n",
    "\n",
    "# 시각화 - original image\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Original ' + image_name)\n",
    "    \n",
    "# 시각화 - submit_csv1\n",
    "    if submit_csv1 != '':\n",
    "        plt.subplot(1, 4, 2)\n",
    "        # 디코딩된 값을 이미지 위에 표시\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        plt.imshow(mask_decoded1, cmap='jet', alpha=0.7)  # alpha 값을 조정하여 투명도 조절\n",
    "        plt.title(submit_csv1)\n",
    "    \n",
    "# 시각화 - submit_csv2\n",
    "    if submit_csv2 != '':\n",
    "        plt.subplot(1, 4, 3)\n",
    "        # 디코딩된 값을 이미지 위에 표시\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        plt.imshow(mask_decoded2, cmap='jet', alpha=0.7)  # alpha 값을 조정하여 투명도 조절\n",
    "        plt.title(submit_csv2)\n",
    "        \n",
    "# 시각화 - submit_csv3\n",
    "    if submit_csv3 != '':\n",
    "        plt.subplot(1, 4, 4)\n",
    "        # 디코딩된 값을 이미지 위에 표시\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        plt.imshow(mask_decoded3, cmap='jet', alpha=0.7)  # alpha 값을 조정하여 투명도 조절\n",
    "        plt.title(submit_csv3)\n",
    "              \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "submit_csv1 #= 'submit(DeepUNet 0.).csv'\n",
    "submit_csv2 #= 'submit(DeepUNet 0.).csv'\n",
    "submit_csv3 #= 'submit(DeepUNet 0.).csv'\n",
    "        \n",
    "for i in range(0, 101):\n",
    "    visual(i, submit_csv1, submit_csv2, submit_csv3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
